{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6766a56b-a8aa-40de-a371-6a9721309cc5",
   "metadata": {},
   "source": [
    "# NLTK: part 2\n",
    "## 01. Part of Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdabf44-de84-4ef2-bc8f-746112e75ae7",
   "metadata": {},
   "source": [
    "* ref: \n",
    "    - [https://pythonprogramming.net](https://pythonprogramming.net)\n",
    "    - [www.geeksforgeeks.org](https://www.geeksforgeeks.org/python-stemming-words-with-nltk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbd97f-6d09-47e7-bec6-58c0688b793e",
   "metadata": {},
   "source": [
    "In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation.\n",
    "\n",
    "    - Input: Everything is all about money.\n",
    "    - Output: [('Everything', 'NN'), ('is', 'VBZ'), \n",
    "          ('all', 'DT'),('about', 'IN'), \n",
    "          ('money', 'NN'), ('.', '.')] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b449a9-5411-440c-ad59-38a1de54ab5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here’s a list of the tags, what they mean, and some examples:\n",
    "\n",
    "- **CC**: coordinating conjunction\n",
    "- **CD**: cardinal digit\n",
    "- **DT**: determiner\n",
    "- **EX**: existential there (like: “there is” … think of it like “there exists”)\n",
    "- **FW**: foreign word\n",
    "- **IN**: preposition/subordinating conjunction\n",
    "- **JJ**: adjective ‘big’\n",
    "- **JJR**: adjective, comparative ‘bigger’\n",
    "- **JJS**: adjective, superlative ‘biggest’\n",
    "- **LS**: list marker 1)\n",
    "- **MD**: modal could, will\n",
    "- **NN**: noun, singular ‘desk’\n",
    "- **NNS**: noun plural ‘desks’\n",
    "- **NNP**: proper noun, singular ‘Harrison’\n",
    "- **NNPS**: proper noun, plural ‘Americans’\n",
    "- **PDT**: predeterminer ‘all the kids’\n",
    "- **POS**: possessive ending parent‘s\n",
    "- **PRP**: personal pronoun I, he, she\n",
    "- **PRP$$**: possessive pronoun my, his, hers\n",
    "- **RB**: adverb very, silently,\n",
    "- **RBR**: adverb, comparative better\n",
    "- **RBS**: adverb, superlative best\n",
    "- **RP**: particle give up\n",
    "- **TO**: to go ‘to‘ the store.\n",
    "- **UH**: interjection errrrrrrrm\n",
    "- **VB**: verb, base form take\n",
    "- **VBD**: verb, past tense took\n",
    "- **VBG**: verb, gerund/present participle taking\n",
    "- **VBN**: verb, past participle taken\n",
    "- **VBP**: verb, sing. present, non-3d take\n",
    "- **VBZ**: verb, 3rd person sing. present takes\n",
    "- **WDT**: wh-determiner which\n",
    "- **WP**: wh-pronoun who, what\n",
    "- **WP$**: possessive wh-pronoun whose\n",
    "- **WRB**: wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57dfe3e-3a06-44f9-b07c-f42c73e49277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8491a6-2373-4d8a-8cec-6f92fb837c8a",
   "metadata": {},
   "source": [
    "`PunktSentenceTokenizer`. This tokenizer is capable of unsupervised machine learning, so you can actually train it on any body of text that you use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed275ba1-2034-4945-b9bc-585e2d41dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create our training and testing data:\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162858d4-2e79-4857-942c-d691e1940d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744eaf5f-70be-4218-83cd-f1a335a05ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "# ag all of the parts of speech per sentence\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8e4fd-97bf-4795-824b-95bb4c4b02ed",
   "metadata": {},
   "source": [
    "## 02. Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a39c3d-bb99-4334-b068-e1bddb681873",
   "metadata": {},
   "source": [
    "`chunking`, and **group words** into hopefully meaningful chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90bd227-deac-4414-90bc-cc5d88220a96",
   "metadata": {},
   "source": [
    "Parsing the sentence with `RegExParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7caed1-b69b-4ae5-bd5b-e203a36d7eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(Chunk Mr./NNP Speaker/NNP)\n",
      "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "(Chunk Congress/NNP)\n",
      "(Chunk Supreme/NNP Court/NNP)\n",
      "(Chunk called/VBD America/NNP)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for ind,i in enumerate(tokenized):\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            if ind < 2:\n",
    "                #print(chunked)\n",
    "                for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                    print(subtree)\n",
    "\n",
    "            #chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4730b-bf61-4e06-b737-29635ee1758d",
   "metadata": {},
   "source": [
    "## 03. Chinking with NLTK\n",
    "\n",
    "`Chinking` is a lot like chunking, it is basically a way for you to `remove a chunk from a chunk`. The chunk that you remove from your chunk is your chink."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8eddd-fb9d-4d08-b488-aa4d437c5686",
   "metadata": {},
   "source": [
    "- the main difference here is:\n",
    "\n",
    "`}<VB.?|IN|DT|TO>+{`\n",
    "\n",
    "- This means we're removing from the chink one or more `verbs`, `prepositions`, `determiners`, or the word `'to'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80db5b0f-f2a4-4a85-a2d0-3fb41b45b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(Chunk Mr./NNP Speaker/NNP)\n",
      "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "(Chunk Congress/NNP)\n",
      "(Chunk Supreme/NNP Court/NNP)\n",
      "(Chunk America/NNP)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for ind,i in enumerate(tokenized):\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<NNP>+<NN>?}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            if ind < 2:\n",
    "                #chunked.draw()\n",
    "                for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                    print(subtree)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
