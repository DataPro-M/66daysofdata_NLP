{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5bb429-4f99-474c-800b-489d0c79165c",
   "metadata": {},
   "source": [
    "# day 5 of #66daysofdata_NLP\n",
    "## NLTK: part 4\n",
    "## 01. Scikit-Learn Sklearn with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5835039-8eb4-49c6-a9bc-0fbd9bdb7d78",
   "metadata": {},
   "source": [
    "* ref: \n",
    "    - [https://pythonprogramming.net](https://pythonprogramming.net)\n",
    "    - [https://nanonets.com](https://nanonets.com/blog/named-entity-recognition-with-nltk-and-spacy/#what-is-named-entity-recognition)\n",
    "    - [https://alvinntnu.github.io](https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/nlp/ml-simple-case.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b4e4e-e2f4-4d1f-99ea-42d36d6584b6",
   "metadata": {},
   "source": [
    "By loading  SklearnClassifier from NLTK you can can use just about any of the sklearn classifiers: \n",
    "- a couple more variations of the Naive Bayes algorithm: `MultinomialNB`,`BernoulliNB` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df2fb16-0f2c-48ea-a7a4-bc86b25d12ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step One: Import nltk and download necessary packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "# some more classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd832c07-8fcc-4b60-b69c-917c1ad510d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firs 5 words of a Sample pos review: \n",
      "['it', \"'\", 's', 'not', 'often'] \n",
      "\n",
      "The 3 most common words and their counts: \n",
      "[(',', 77717), ('the', 76529), ('.', 65876)]\n",
      "\n",
      "An Example of first 5 words of a sample featureset of a neg review:\n",
      "{'plot': True, ':': True, 'two': False, 'teen': False, 'couples': False}, label --> neg \n",
      "('True' means the word is in top 3,000 most common words)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing set (see prev. tutorial)\n",
    "\n",
    "def movie_reviews_to_features(verbose=0):\n",
    "    # In each category (we have pos or neg), take all of the file IDs (each review has its own ID), \n",
    "    # then store the word_tokenized version (a list of words) for the file ID, \n",
    "    # followed by the positive or negative label in one big list. \n",
    "    documents = [(list(movie_reviews.words(fileid)), category)\n",
    "                 for category in movie_reviews.categories()\n",
    "                 for fileid in movie_reviews.fileids(category)]\n",
    "    \n",
    "    #  random to shuffle our documents. This is because we're going to be training and testing. \n",
    "    random.shuffle(documents)\n",
    "    # sample word_tokenized version of a review\n",
    "    # where the first element is a list the words, and the 2nd element is the \"pos\" or \"neg\" label.\n",
    "    if verbose ==1:\n",
    "        print('Firs 5 words of a Sample {} review: \\n{}'.format(documents[1][1],documents[1][0][:5]),'\\n')\n",
    "\n",
    "    all_words = []\n",
    "    for w in movie_reviews.words():\n",
    "        all_words.append(w.lower())\n",
    "\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    if verbose ==1:\n",
    "        print('The 3 most common words and their counts: \\n{}\\n'.format(all_words.most_common(3)))\n",
    "    # word_features: contains the top 3,000 most common words.\n",
    "    word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "    # find these top 3,000 words in our positive and negative documents,\n",
    "    # marking their presence as either positive or negative\n",
    "    def find_features(document):\n",
    "        words = set(document)\n",
    "        features = {}\n",
    "        for w in word_features:\n",
    "            features[w] = (w in words)\n",
    "\n",
    "        return features\n",
    "    featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "    if verbose ==1:\n",
    "        print(\"An Example of first 5 words of a sample featureset of a {} review:\\n{}, label --> {} \\n('True' means the word is in top 3,000 most common words)\".\n",
    "              format(featuresets[0][1],{k: featuresets[0][0][k] for k in list(featuresets[0][0])[:5]}, featuresets[0][1]))\n",
    "    return featuresets\n",
    "\n",
    "\n",
    "featuresets = movie_reviews_to_features(verbose=1)\n",
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bee2324-c96e-45e2-bc62-e483f122de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, model_name, train_set, n_splits=10):\n",
    "    import sklearn.model_selection\n",
    "    kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    acc_kf = []  ## accuracy holder\n",
    "\n",
    "    ## Cross-validation\n",
    "    for train_index, test_index in kf.split(train_set):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        train_fold = train_set[train_index[0]:train_index[len(train_index) - 1]]\n",
    "        test_fold  = train_set[test_index[0]:test_index[len(test_index) - 1]]\n",
    "        \n",
    "        classifier   = model.train(train_fold)\n",
    "        cur_fold_acc = nltk.classify.util.accuracy(classifier, test_fold)\n",
    "        \n",
    "        acc_kf.append(cur_fold_acc*100)\n",
    "    print('{} accuracy: {} +-% {}'.format(model_name, np.mean(acc_kf),np.std(acc_kf)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192cc806-7edf-4374-b739-7ad98442cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy: 88.04232804232804 +-% 3.1140611575792927\n"
     ]
    }
   ],
   "source": [
    "cross_val(nltk.NaiveBayesClassifier,'Original Naive Bayes Algo', training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dae79ad-e187-49d7-b27e-a3538870c6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 79.0\n",
      "Most Informative Features\n",
      "                   sucks = True              neg : pos    =      9.7 : 1.0\n",
      "                  justin = True              neg : pos    =      9.6 : 1.0\n",
      "                  annual = True              pos : neg    =      9.1 : 1.0\n",
      "                 frances = True              pos : neg    =      9.1 : 1.0\n",
      "                 idiotic = True              neg : pos    =      8.9 : 1.0\n",
      "MNB_classifier accuracy percent: 83.0\n",
      "BernoulliNB_classifier accuracy percent: 79.0\n",
      "LogisticRegression_classifier accuracy percent: 84.0\n",
      "SGDClassifier_classifier accuracy percent: 73.0\n",
      "SVC_classifier accuracy percent: 81.0\n",
      "LinearSVC_classifier accuracy percent: 83.0\n",
      "NuSVC_classifier accuracy percent: 83.0\n"
     ]
    }
   ],
   "source": [
    "# Next, we can define, and train our classifier like:\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(5)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
